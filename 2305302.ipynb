{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "说明：本项目提交时忘记保留checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pgl\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/4f/77/f7da1735b936a9ce1b199d7d0cf00379d8c53f3f6ae7ca93ec585fe2342f/pgl-2.1.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 15.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (1.20.3)\n",
      "Requirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl) (0.29)\n",
      "Installing collected packages: pgl\n",
      "Successfully installed pgl-2.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pgl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import pandas as pd\r\n",
    "import pgl\r\n",
    "import tqdm\r\n",
    "from paddle.optimizer import Adam\r\n",
    "from paddle.optimizer import Momentum\r\n",
    "from easydict import EasyDict as edict\r\n",
    "import paddle.fluid as F\r\n",
    "import paddle.fluid.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dataset = namedtuple(\"Dataset\",\r\n",
    "                     [\"graph\", \"num_classes\", \"train_index\", \"train_label\", \"valid_index\", \"valid_label\", \"test_index\", \"test_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_edges(num_nodes, self_loop=True, add_inverse_edge=True):\r\n",
    "    # 从数据中读取边\r\n",
    "    edges = pd.read_csv(r\"/home/aistudio/data/data61620/edges.csv\", header=None,\r\n",
    "                        names=[\"src\", \"dst\"]).values\r\n",
    "\r\n",
    "    if add_inverse_edge:\r\n",
    "        edges = np.vstack([edges, edges[:, ::-1]])\r\n",
    "\r\n",
    "    if self_loop:\r\n",
    "        src = np.arange(0, num_nodes)\r\n",
    "        dst = np.arange(0, num_nodes)\r\n",
    "        self_loop = np.vstack([src, dst]).T\r\n",
    "        edges = np.vstack([edges, self_loop])\r\n",
    "\r\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load():\r\n",
    "    # 从数据中读取点特征和边，以及数据划分\r\n",
    "    node_feat = np.load(r\"/home/aistudio/data/data61620/feat.npy\")\r\n",
    "    num_nodes = node_feat.shape[0]\r\n",
    "    edges = load_edges(num_nodes=num_nodes, self_loop=True, add_inverse_edge=True)\r\n",
    "    graph = pgl.graph.Graph(num_nodes=num_nodes, edges=edges, node_feat={\"feat\": node_feat})\r\n",
    "\r\n",
    "    in_degree = graph.indegree()\r\n",
    "    norm = np.maximum(in_degree.astype(\"float32\"), 1)\r\n",
    "    norm = np.power(norm, -0.5)\r\n",
    "    graph.node_feat[\"norm\"] = paddle.to_tensor(np.expand_dims(norm, -1))\r\n",
    "\r\n",
    "    df = pd.read_csv(r\"/home/aistudio/data/data61620/train.csv\")\r\n",
    "    node_index = df[\"nid\"].values\r\n",
    "    node_label = df[\"label\"].values\r\n",
    "    train_part = int(len(node_index) * 0.8)\r\n",
    "    train_idx = paddle.to_tensor(node_index[:train_part])\r\n",
    "    train_lbl = paddle.to_tensor(np.expand_dims(node_label[:train_part], -1))\r\n",
    "    valid_index = paddle.to_tensor(node_index[train_part:])\r\n",
    "    valid_label = paddle.to_tensor(np.expand_dims(node_label[train_part:], -1))\r\n",
    "    test_idx = paddle.to_tensor(pd.read_csv(r\"/home/aistudio/data/data61620/test.csv\")[\"nid\"].values)\r\n",
    "    test_label = paddle.to_tensor(np.zeros((len(test_idx), 1), dtype=\"int64\"))\r\n",
    "\r\n",
    "    graph_ds = Dataset(graph=graph.tensor(),\r\n",
    "                       train_label=train_lbl,\r\n",
    "                       train_index=train_idx,\r\n",
    "                       valid_index=valid_index,\r\n",
    "                       valid_label=valid_label,\r\n",
    "                       test_index=test_idx,\r\n",
    "                       test_label=test_label,\r\n",
    "                       num_classes=35)\r\n",
    "    return graph_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Layer):\r\n",
    "    \"\"\"Implement of GCN\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self,\r\n",
    "                 input_size,\r\n",
    "                 num_class,\r\n",
    "                 num_layers=1,\r\n",
    "                 hidden_size=64,\r\n",
    "                 dropout=0.5,\r\n",
    "                 **kwargs):\r\n",
    "        super(GCN, self).__init__()\r\n",
    "        self.num_class = num_class\r\n",
    "        self.num_layers = num_layers\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.dropout = dropout\r\n",
    "        self.gcn_s = nn.LayerList()\r\n",
    "        for i in range(self.num_layers):\r\n",
    "            if i == 0:\r\n",
    "                self.gcn_s.append(\r\n",
    "                    pgl.nn.GCNConv(\r\n",
    "                        input_size,\r\n",
    "                        self.hidden_size,\r\n",
    "                        activation=\"relu\",\r\n",
    "                        norm=True))\r\n",
    "            else:\r\n",
    "                self.gcn_s.append(\r\n",
    "                    pgl.nn.GCNConv(\r\n",
    "                        self.hidden_size,\r\n",
    "                        self.hidden_size,\r\n",
    "                        activation=\"relu\",\r\n",
    "                        norm=True))\r\n",
    "            self.gcn_s.append(nn.Dropout(self.dropout))\r\n",
    "        self.gcn_s.append(pgl.nn.GCNConv(self.hidden_size, self.num_class))\r\n",
    "\r\n",
    "    def forward(self, graph, feature):\r\n",
    "        for m in self.gcn_s:\r\n",
    "            if isinstance(m, nn.Dropout):\r\n",
    "                feature = m(feature)\r\n",
    "            else:\r\n",
    "                feature = m(graph, feature)\r\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GCNRes(nn.Layer):\r\n",
    "    \"\"\"Implement of GCNRes\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self,\r\n",
    "                 input_size,\r\n",
    "                 num_class,\r\n",
    "                 num_layers=1,\r\n",
    "                 feat_drop=0.6,\r\n",
    "                 hidden_size=64,\r\n",
    "                 dropout = 0.5,\r\n",
    "                 **kwargs):\r\n",
    "        super(GCNRes, self).__init__()\r\n",
    "        self.input_size = input_size\r\n",
    "        self.num_class = num_class\r\n",
    "        self.num_layers = num_layers\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.dropout = dropout\r\n",
    "        self.gcns = nn.LayerList()\r\n",
    "\r\n",
    "        self.linear = nn.Linear(input_size, self.hidden_size, name='initialize_feature')\r\n",
    "\r\n",
    "        for i in range(self.num_layers):\r\n",
    "            self.gcns.append(\r\n",
    "                pgl.nn.GCNConv(self.hidden_size,\r\n",
    "                               self.hidden_size, activation=None, norm=False))\r\n",
    "\r\n",
    "        self.gcns.append(\r\n",
    "            pgl.nn.GCNConv(self.hidden_size,\r\n",
    "                           self.num_class, activation=None, norm=False))\r\n",
    "\r\n",
    "    def forward(self, graph, feature):\r\n",
    "        # 先来个全连接层\r\n",
    "        feature = self.linear(feature)\r\n",
    "        feature = paddle.nn.functional.layer_norm(feature, self.hidden_size)\r\n",
    "        feature = paddle.nn.functional.dropout(feature, self.dropout)\r\n",
    "\r\n",
    "        for x in range(self.num_layers):\r\n",
    "            res_feature = feature\r\n",
    "            feature = self.gcns[x](graph, feature)\r\n",
    "            feature = res_feature + feature\r\n",
    "            feature = paddle.nn.functional.relu(feature)\r\n",
    "            feature = paddle.nn.functional.layer_norm(feature, normalized_shape=self.hidden_size)\r\n",
    "        feature = self.gcns[-1](graph, feature)\r\n",
    "        feature = paddle.nn.functional.relu(feature)\r\n",
    "        feature = paddle.nn.functional.layer_norm(feature, normalized_shape=self.num_class)\r\n",
    "        \r\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(node_index, node_label, gnn_model, graph, criterion, opt):\r\n",
    "    gnn_model.train()\r\n",
    "    pred = gnn_model(graph, graph.node_feat[\"feat\"])\r\n",
    "    pred = paddle.gather(pred, node_index)\r\n",
    "    loss = criterion(pred, node_label)\r\n",
    "    loss.backward()\r\n",
    "    #acc = accuracy.compute(pred=pred, label=node_label)\r\n",
    "    acc = paddle.metric.accuracy(input=pred, label=node_label, k=1)\r\n",
    "    opt.minimize(loss)\r\n",
    "    #opt.step()\r\n",
    "    opt.clear_grad()\r\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@paddle.no_grad()\r\n",
    "def eval(node_index, node_label, gnn_model, graph, criterion):\r\n",
    "    gnn_model.eval()\r\n",
    "    pred = gnn_model(graph, graph.node_feat[\"feat\"])\r\n",
    "    pred = paddle.gather(pred, node_index)\r\n",
    "    loss = criterion(pred, node_label)\r\n",
    "    #acc = accuracy.compute(pred=pred, label=node_label)\r\n",
    "    acc = paddle.metric.accuracy(input=pred, label=node_label, k=1)\r\n",
    "    pred = np.argmax(pred, axis=1)\r\n",
    "    return loss, acc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entrance(dataset, cfg):\r\n",
    "    graph = dataset.graph\r\n",
    "    train_index_ = dataset.train_index\r\n",
    "    train_label_ = dataset.train_label\r\n",
    "\r\n",
    "    val_index_ = dataset.valid_index\r\n",
    "    val_label_ = dataset.valid_label\r\n",
    "\r\n",
    "    test_index_ = dataset.test_index\r\n",
    "    test_label = dataset.test_label\r\n",
    "\r\n",
    "    graph_model = GCNRes\r\n",
    "    criterion = paddle.nn.loss.CrossEntropyLoss()\r\n",
    "\r\n",
    "    dur = []\r\n",
    "    \r\n",
    "    best_test_labels = []\r\n",
    "\r\n",
    "    for run in range(20):\r\n",
    "        cal_val_acc = []\r\n",
    "        cal_test_acc = []\r\n",
    "        cal_val_loss = []\r\n",
    "        cal_test_loss = []\r\n",
    "        test_labels = []\r\n",
    "\r\n",
    "        gnn_model = graph_model(\r\n",
    "            input_size=graph.node_feat[\"feat\"].shape[1],\r\n",
    "            num_class=dataset.num_classes,\r\n",
    "            **cfg)\r\n",
    "\r\n",
    "        optimizer = Adam(\r\n",
    "            learning_rate=cfg.learning_rate,\r\n",
    "            parameters=gnn_model.parameters(),\r\n",
    "            weight_decay=cfg.weight_decay)\r\n",
    "\r\n",
    "        for epoch in range(1001):\r\n",
    "            train_loss, train_acc = train(train_index_, train_label_, gnn_model,\r\n",
    "                                          graph, criterion, optimizer)\r\n",
    "\r\n",
    "            if(epoch % 10==0):\r\n",
    "                print('%-9s%-10s%-20s%-20s' %('Runs {0}-'.format(run), 'Epochs {0}'.format(epoch), '-train loss: {0}'.format(train_loss.numpy()), '-train acc: {0}'.format(train_acc.numpy())))\r\n",
    "                val_loss, val_acc, val_pred = eval(val_index_, val_label_, gnn_model, graph, criterion)\r\n",
    "                print('%-9s%-10s%-20s%-20s' %('Runs {0}-'.format(run), 'Epochs {0}'.format(epoch), '-val   loss: {0}'.format(val_loss.numpy()), '-val   acc: {0}'.format(val_acc.numpy())))\r\n",
    "                cal_val_acc.append(val_acc.numpy())\r\n",
    "                cal_val_loss.append(val_loss.numpy())\r\n",
    "                \r\n",
    "                test_loss, test_acc, test_pred = eval(test_index_, test_label, gnn_model,\r\n",
    "                                       graph, criterion)\r\n",
    "                cal_test_acc.append(test_acc.numpy())\r\n",
    "                cal_test_loss.append(test_loss.numpy())\r\n",
    "                test_labels.append(test_pred)\r\n",
    "\r\n",
    "        test_prediction = test_labels[np.argmax(cal_val_acc)]\r\n",
    "        submission = pd.DataFrame(data={\"nid\": test_index_,\"label\": test_prediction})\r\n",
    "        submission.to_csv(\"2021-8-31/submission-{0}.csv\".format(cal_val_acc[np.argmax(cal_val_acc)]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gcn_config = {\r\n",
    "    \"model_name\": \"GCNRes\",\r\n",
    "    \"num_layers\": 3,\r\n",
    "    \"dropout\": 0.15,\r\n",
    "    'hidden_size': 128,\r\n",
    "    \"learning_rate\": 0.00125,\r\n",
    "    \"weight_decay\": 0.0005,\r\n",
    "    \"edge_dropout\": 0.00,\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph_dataset = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs 19- Epochs 1000-val   loss: [1.0094459]-val   acc: [0.7304051]\r"
     ]
    }
   ],
   "source": [
    "entrance(graph_dataset, edict(gcn_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "def vote_merge(pth, filelst):\r\n",
    "    result = {}\r\n",
    "    fw = open('submission.csv', encoding='utf-8', mode='w', newline='')\r\n",
    "    csv_writer = csv.writer(fw)\r\n",
    "    csv_writer.writerow(['nid', 'label'])\r\n",
    "    for filepath in filelst:\r\n",
    "        cr = open(pth+filepath, encoding='utf-8', mode='r')\r\n",
    "        csv_reader = csv.reader(cr)\r\n",
    "        for i, row in enumerate(csv_reader):\r\n",
    "            if i == 0:\r\n",
    "                continue\r\n",
    "            idx, cls = row\r\n",
    "            if idx not in result:\r\n",
    "                result[idx] = []\r\n",
    "            result[idx].append(cls)\r\n",
    "\r\n",
    "    for nid, clss in result.items():\r\n",
    "        counter = Counter(clss)\r\n",
    "        true_cls = counter.most_common(1)\r\n",
    "        csv_writer.writerow([nid, true_cls[0][0]])\r\n",
    "    print('write csv done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submission-[0.7366698].csv', 'submission-[0.7330391].csv', 'submission-[0.7385207].csv', 'submission-[0.7380223].csv', 'submission-[0.736029].csv', 'submission-[0.7365274].csv', 'submission-[0.7376664].csv', 'submission-[0.7363138].csv', 'submission-[0.73659855].csv', 'submission-[0.73553073].csv', 'submission-[0.733751].csv', 'submission-[0.7343205].csv', 'submission-[0.7333238].csv', 'submission-[0.7351748].csv', 'submission-[0.7349612].csv', 'submission-[0.736385].csv', 'submission-[0.73645616].csv', 'submission-[0.7371681].csv', 'submission-[0.73859185].csv']\n",
      "['submission-[0.73859185].csv', 'submission-[0.7385207].csv', 'submission-[0.7380223].csv', 'submission-[0.7376664].csv', 'submission-[0.7371681].csv', 'submission-[0.7366698].csv', 'submission-[0.73659855].csv', 'submission-[0.7365274].csv', 'submission-[0.73645616].csv', 'submission-[0.736385].csv', 'submission-[0.7363138].csv', 'submission-[0.736029].csv', 'submission-[0.73553073].csv', 'submission-[0.7351748].csv', 'submission-[0.7349612].csv', 'submission-[0.7343205].csv', 'submission-[0.733751].csv', 'submission-[0.7333238].csv', 'submission-[0.7330391].csv']\n",
      "['submission-[0.73859185].csv', 'submission-[0.7385207].csv', 'submission-[0.7380223].csv', 'submission-[0.7376664].csv', 'submission-[0.7371681].csv', 'submission-[0.7366698].csv', 'submission-[0.73659855].csv', 'submission-[0.7365274].csv', 'submission-[0.73645616].csv', 'submission-[0.736385].csv']\n",
      "write csv done\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "import pandas as pd\r\n",
    "#path放的是你所有的提交文件\r\n",
    "path = '/home/aistudio/2021-8-31'\r\n",
    "\r\n",
    "filelist = []\r\n",
    "for root, dirs, files in os.walk(path):\r\n",
    "    for f in files:\r\n",
    "        if f.endswith('csv'):\r\n",
    "            filelist.append(f)\r\n",
    "                \r\n",
    "print(filelist)\r\n",
    "\r\n",
    "# 下面这行代码按照测试精度进行排序\r\n",
    "filelist = sorted(filelist, key= lambda x:float(x[12:-5]), reverse=True)\r\n",
    "print(filelist)\r\n",
    "filelist = filelist[:10]\r\n",
    "print(filelist)\r\n",
    "\r\n",
    "vote_merge('/home/aistudio/2021-8-31/', filelist)\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
